import streamlit as st

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –Ω–∞ —à–∏—Ä–æ–∫–∏–π —Ä–µ–∂–∏–º
st.set_page_config(
    page_title="Fashion Image Classification",
    page_icon="üëó",
    layout="wide"
)
import gdown
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import json

# –°–ª–æ–≤–Ω–∏–∫ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤
translations = {
    'en': {
        'page_title': 'Fashion Image Classification using CNN and VGG16',
        'select_model': 'Select Model',
        'about_app': 'About Application',
        'app_description': '''
This application allows you to classify fashion images using:
- Custom Convolutional Neural Network (CNN)
- Modified VGG16 Architecture
        ''',
        'classes': 'Model classifies images into 10 classes:',
        'upload_image': 'Upload an image',
        'uploaded_image': 'Uploaded image',
        'predicted_class': 'Predicted class',        
        'probability_distribution': 'Class Probability Distribution',
        'probability': 'Probability',
        'training_graphs': 'Training Graphs',
        'model_accuracy': 'Model Accuracy',
        'model_loss': 'Model Loss',
        'accuracy': 'Accuracy',
        'loss': 'Loss',
        'epoch': 'Epoch',
        'training': 'Training',
        'validation': 'Validation',
        'model_error': 'Model loading error. Please check model files.',
        'processing_error': 'Error processing image: ',
        'history_unavailable': 'Training history for model {} is unavailable'
    },
    'uk': {
        'page_title': '–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∑–æ–±—Ä–∞–∂–µ–Ω—å –æ–¥—è–≥—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é CNN —Ç–∞ VGG16',
        'select_model': '–í–∏–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å',
        'about_app': '–ü—Ä–æ –∑–∞—Å—Ç–æ—Å—É–Ω–æ–∫',
        'app_description': '''
–¶–µ–π –∑–∞—Å—Ç–æ—Å—É–Ω–æ–∫ –¥–æ–∑–≤–æ–ª—è—î –∫–ª–∞—Å–∏—Ñ—ñ–∫—É–≤–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –æ–¥—è–≥—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é:
- –í–ª–∞—Å–Ω–æ—ó –∑–≥–æ—Ä—Ç–∫–æ–≤–æ—ó –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ (CNN)
- –ú–æ–¥–∏—Ñ—ñ–∫–æ–≤–∞–Ω–æ—ó –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ VGG16
        ''',
        'classes': '–ú–æ–¥–µ–ª—å –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∞ 10 –∫–ª–∞—Å—ñ–≤:',
        'upload_image': '–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è',
        'uploaded_image': '–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è',
        'predicted_class': '–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏–π –∫–ª–∞—Å',        
        'probability_distribution': '–†–æ–∑–ø–æ–¥—ñ–ª –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å–∞—Ö',
        'probability': '–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å',
        'training_graphs': '–ì—Ä–∞—Ñ—ñ–∫–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è',
        'model_accuracy': '–¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ',
        'model_loss': '–í—Ç—Ä–∞—Ç–∏ –º–æ–¥–µ–ª—ñ',
        'accuracy': '–¢–æ—á–Ω—ñ—Å—Ç—å',
        'loss': '–í—Ç—Ä–∞—Ç–∏',
        'epoch': '–ï–ø–æ—Ö–∞',
        'training': '–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è',
        'validation': '–í–∞–ª—ñ–¥–∞—Ü—ñ—è',
        'model_error': '–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ñ–∞–π–ª—ñ–≤ –º–æ–¥–µ–ª–µ–π.',
        'processing_error': '–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: ',
        'history_unavailable': '–Ü—Å—Ç–æ—Ä—ñ—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è –º–æ–¥–µ–ª—ñ {} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞'
    }
}

# –í–∏–±—ñ—Ä –º–æ–≤–∏ —É —Å–∞–π–¥–±–∞—Ä—ñ
language = st.sidebar.selectbox('üåê Language / –ú–æ–≤–∞', ['en', 'uk'], format_func=lambda x: 'English' if x == 'en' else '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞')
t = translations[language]

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≥—Ä–∞—Ñ—ñ–∫—ñ–≤
def plot_training_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # –ì—Ä–∞—Ñ—ñ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ
    ax1.plot(history['accuracy'])
    ax1.plot(history['val_accuracy'])
    ax1.set_title(t['model_accuracy'])
    ax1.set_ylabel(t['accuracy'])
    ax1.set_xlabel(t['epoch'])
    ax1.legend([t['training'], t['validation']], loc='lower right')
    
    # –ì—Ä–∞—Ñ—ñ–∫ –≤—Ç—Ä–∞—Ç
    ax2.plot(history['loss'])
    ax2.plot(history['val_loss'])
    ax2.set_title(t['model_loss'])
    ax2.set_ylabel(t['loss'])
    ax2.set_xlabel(t['epoch'])
    ax2.legend([t['training'], t['validation']], loc='upper right')
    
    return fig

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
@st.cache_resource
def load_cnn_model():
    try:
        model = load_model('cnn_model.keras', compile=False)        
        return model
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è CNN –º–æ–¥–µ–ª—ñ: {str(e)}")
        return None

@st.cache_resource
def load_vgg16_model():
    model_path = "vVGG16_model.keras"
    file_id = "1wF6T2V1_EmjwmPJ4sfeEVWm6ggHQltMw"
    url = f"https://drive.google.com/uc?id={file_id}"
    
    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª, —è–∫—â–æ –≤—ñ–Ω —â–µ –Ω–µ —ñ—Å–Ω—É—î
        if not os.path.exists(model_path):
            with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."):
                gdown.download(url, model_path, quiet=False)

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å
        model = load_model(model_path, compile=False)
        return model

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è VGG16 –º–æ–¥–µ–ª—ñ: {str(e)}")
        return None

# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å
def preprocess_image_for_cnn(img):
    img = img.resize((28, 28))
    img = img.convert('L')  
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    return img_array

def preprocess_image_for_vgg16(img):
    img = img.resize((32, 32))
    img = img.convert('RGB')  
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0
    return img_array

# –Ü–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
st.markdown(f"# :rainbow[{t['page_title']}]")

# –ö–ª–∞—Å-–Ω–∞–∑–≤–∏ –¥–ª—è Fashion MNIST
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# –í–∏–±—ñ—Ä –º–æ–¥–µ–ª—ñ
model_option = st.sidebar.selectbox(t['select_model'], ['CNN', 'VGG16'])

# –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
st.sidebar.markdown("---")
st.sidebar.write(f"### {t['about_app']}")
st.sidebar.write(t['app_description'])
st.sidebar.write(t['classes'])
st.sidebar.write("\n".join([f"- {name}" for name in class_names]))

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
if model_option == 'CNN':
    model = load_cnn_model()
else:
    model = load_vgg16_model()

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
uploaded_file = st.file_uploader(t['upload_image'], type=["png", "jpg", "jpeg"])

if uploaded_file is not None and model is not None:
    try:
        img = image.load_img(uploaded_file)
        st.image(img, caption=t['uploaded_image'], width=400)

        if model_option == 'CNN':
            img_array = preprocess_image_for_cnn(img)
        else:
            img_array = preprocess_image_for_vgg16(img)

        # –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        prediction = model.predict(img_array)       
        
        predicted_class = class_names[np.argmax(prediction)]
        confidence = np.max(prediction) * 100
        
        st.success(f"**{t['predicted_class']}:** {predicted_class} ({t['probability']}: {confidence:.2f}%)")
        
        col1, col2 = st.columns([2, 1]) 
        with col1:            
            plt.figure(figsize=(12, 6))  
            fig, ax = plt.subplots()
            y_pos = np.arange(len(class_names))
            bars = ax.barh(y_pos, prediction[0] * 100)
            
            ax.set_yticks(y_pos)
            ax.set_yticklabels(class_names, fontsize=10)  
            ax.invert_yaxis()
            ax.set_xlabel(t['probability'] + ' (%)', fontsize=10)  
            ax.set_title(t['probability_distribution'], fontsize=12, pad=15)  
            
            ax.tick_params(axis='x', labelsize=10)
            ax.grid(True, linestyle='--', alpha=0.7)
            
            for i, v in enumerate(prediction[0] * 100):
                ax.text(v + 1, i, f'{v:.1f}%', va='center', fontsize=9)
            
            plt.tight_layout()
            st.pyplot(fig)
        
    except Exception as e:
        st.error(f"{t['processing_error']}{str(e)}")

    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
    try:
        history_file = 'cnn_training_history.json' if model_option == 'CNN' else 'VGG16_training_history.json'
        with open(history_file, 'r') as f:
            history = json.load(f)
            st.write(f"### {t['training_graphs']}:")
            st.pyplot(plot_training_history(history))
    except Exception as e:
        st.info(t['history_unavailable'].format(model_option))

elif model is None:
    st.error(t['model_error'])